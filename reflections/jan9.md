# January 9th

In "The Trouble With Creativity," Baer makes a strong case for the domain-specific nature of creativity, overwhelmingly supported by the experimental results he cites.
While so doing, he introduces several tests used in creativity studies, such as the CAT ("Consensual Assessment Technique").
Baer briefly mentions that this test relies on the evaluations of domain experts, and Schneiderman also acknowledges the role of domain "gatekeepers" in validating creative contributions.
While this is presented as a breakthrough, it seems to me like a potential methodological weakness, especially when judging things as subjective as paintings, poems, or musical compositions.
It appears self-evident to me that a group of experts in one of these well-established fields would exhibit biases (aesthetic and otherwise) shaped by the field itself, which would likely be reinforced and amplified by the group.
Furthermore, critics generally tend toward conservatism, which prefers appropriateness over novelty. Which poses the question: which is more important to creativity?

Although a later section of the article warns of the limitations of self-reporting in creativity trait studies, it seems to me that it may be more relevant when investigating the efficacy of creativity support tools.
After all, who would be in a better position to judge their own relative creativity than the subjects themselves?
I wonder if there could be value in a hybrid method: self-reporting, to determine if the subject feels more or less creative when using a specific tool, followed by external evaluation, to somehow grade the novelty and value of the artifact.
Of course, the question of who gets to conduct this second evaluation is of critical importance.
